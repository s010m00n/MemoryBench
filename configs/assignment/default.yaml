# Lifelong Learning Benchmark Configuration
# 配置要测试的任务、记忆机制、执行方法和实验参数

# ===== 任务配置 =====
# 指定要测试的任务列表（5个system memory任务+2个user memory任务，共7个任务）
tasks:
  # system memory任务
  # - name: dbbench-std
  #   config_path: configs/tasks/dbbench.yaml
  - name: os-std
    config_path: configs/tasks/os.yaml
  # - name: kg-std
  #   config_path: configs/tasks/kg.yaml
  # - name: alfworld-std
  #   config_path: configs/tasks/alfworld.yaml
  # - name: webshop-std
  #   config_path: configs/tasks/webshop.yaml

  # user memory任务
  # - name: locomo-0
  #   config_path: configs/tasks/locomo-0.yaml
  # - name: locomo-1
  #   config_path: configs/tasks/locomo-1.yaml
  # - name: locomo-2
  #   config_path: configs/tasks/locomo-2.yaml
  # - name: locomo-3
  #   config_path: configs/tasks/locomo-3.yaml
  # - name: locomo-4
  #   config_path: configs/tasks/locomo-4.yaml
  # - name: locomo-5
  #   config_path: configs/tasks/locomo-5.yaml
  # - name: locomo-6
  #   config_path: configs/tasks/locomo-6.yaml
  # - name: locomo-7
  #   config_path: configs/tasks/locomo-7.yaml
  # - name: locomo-8
  #   config_path: configs/tasks/locomo-8.yaml
  # - name: locomo-9
  #   config_path: configs/tasks/locomo-9.yaml

# ===== 记忆机制配置 =====
# 从 memory 文件夹中选择记忆机制（统一使用 snake_case 命名）
memory_mechanism:
  name: awm_pro  # 可选: zero_shot, stream_icl, mem0, awm_pro, mems

# ===== 执行方法配置 =====
# 从 execution 文件夹中选择执行方法
execution_method:
  name: single_agent  # 当前版本仅支持 single_agent
  config_path: execution/single_agent/single_agent.yaml

# ===== 实验参数 =====
experiment:
  # 训练模式: online (在线学习) 或 offline (离线学习) 或 replay (重放学习) 或 transfer (迁移学习) 
  training_mode: online  # online | offline | replay | transfer
  
  keep_number: 700 #只有training_mode等于online时，这个参数才有效 #为None或者小于等于0，则不进行截断

  train_size: 0.7 #只有training_mode等于offline时，这个参数才有效

  #在transfer_task中学习（update+enhance，相当于online），在transfer_after_task中进行测试（仅enhance）
  transfer_task: dbbench-std #只有training_mode等于transfer时，这个参数才有效
  transfer_after_task: locomo-0 #只有training_mode等于transfer时，这个参数才有效

  #这两个参数的意思是，每学过m个样本（update+enhance，相当于online），就从学过的所有样本中随机抽样n个进行测试（仅enhance）
  replay_m: 19 #只有training_mode等于replay时，这个参数才有效
  replay_n: 19 #只有training_mode等于replay时，这个参数才有效
  replay_seed: 1 #只有training_mode等于replay时，这个参数才有效

  # 跨任务学习: 是否允许跨任务的知识传递和学习
  # - offline 模式：
  #   * 不支持 cross_task=True，会报错
  #   * 必须 cross_task=False，且只能选中一个数据集
  # - online 模式：
  #   * 若 cross_task=True, shuffle=True：全体 shuffle，跨任务知识共享
  #   * 若 cross_task=False, shuffle=True：只 shuffle 当前任务，任务切换时清空 memory
  #   * 若 cross_task=True, shuffle=False：报错（需要 shuffle 才能跨任务）
  #   * cross_task=False 时，必须只能选中一个数据集（否则会报错）
  #   * cross_task=True 时，必须选中大于一个数据集（否则会报错）
  # - transfer 模式（迁移学习）：
  #   * 必须 cross_task=True（不支持 cross_task=False，不支持locomo）
  #   * 必须选中两个任务：transfer_task 和 transfer_after_task
  #   * 选中的任务必须包含 transfer_task 和 transfer_after_task
  #   * 如果 shuffle.enabled=True，两个任务各自 shuffle，都使用 shuffle.seed
  # - replay 模式（重放学习）：
  #   * 必须 cross_task=False（不支持 cross_task=True）
  #   * 必须只选中一个任务
  #   * 如果 shuffle.enabled=True，训练样本使用 shuffle.seed 进行 shuffle
  #   * 测试样本随机抽样使用 replay_seed（不涉及 shuffle）
  cross_task: False  # True | False

  # 数据打乱: 是否打乱任务顺序，可以设置随机种子
  shuffle:
    enabled: True  # True | False
    seed: 66  # 整数，如果 enabled 为 true 时使用